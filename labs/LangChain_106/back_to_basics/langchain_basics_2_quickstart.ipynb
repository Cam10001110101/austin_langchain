{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Quickstart\n",
    "This quickstart is meant to guide the user through the basics of building and interacting with a LLM using langchain\n",
    "It is update from March 2024, and based of the LangChain docs found here - https://python.langchain.com/docs/get_started/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (0.1.13)\n",
      "Requirement already satisfied: langchain-openai in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (0.0.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (0.1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (0.1.29)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain-openai) (1.14.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's make this work with Google Colab by default. Uncomments the commented items below if you want to use this on a local notebook\n",
    "# import getpass\n",
    "# import os\n",
    "# import uuid\n",
    "# from google.colab import userdata\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
    "\n",
    "# def _set_if_undefined(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "# _set_if_undefined(\"OPENAI_API_KEY\")\n",
    "# _set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Optional, add tracing in LangSmith.\n",
    "# This will help you visualize and debug the control flow\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\"\n",
    "\n",
    "# Uncomment below if you want to enter the API key manually\n",
    "#os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "#Uncomment below if you want to use .env file\n",
    "import os\n",
    "import uuid\n",
    "import dotenv\n",
    "\n",
    "#load the .env file from the default location\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "#retrieve the openai key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#check if OPENAI_API_KEY is not NONE and set it\n",
    "if openai_api_key:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "else:\n",
    "    # If OPENA_AI_API_KEY is not set, prompt the user to enter the key\n",
    "    print(\"OPENAI_API_KEY not found in the .env file\")\n",
    "# Optional, add tracing in LangSmith.\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"quickstart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm not sure, as I do not have real-time information on music events. I recommend checking local music venues, event websites, or social media pages for information on bands playing in Austin tonight. Some popular venues in Austin known for hosting great live music include Mohawk, Stubbs BBQ, Antone's, and The Continental Club.\", response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 17, 'total_tokens': 85}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What great bands are playing music in Austin tonight?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class event planner, with amazing documentation kills.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I do not have real-time information on specific events happening in Austin tonight. However, Austin is known for its vibrant music scene, so there are likely many great bands playing in various venues around the city. I recommend checking local event listings, music venues' websites, or social media platforms to find out which bands are performing in Austin tonight. Enjoy the live music scene in the Live Music Capital of the World!\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What great bands are playing music in Austin tonight?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default output of ChatModel is a message. It's more convienient to work with strings. We'll use StrOutputParser to convert the chat message to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cha now add this parser to the previous chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now invoke it and ask the same question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can't provide real-time information on specific events happening in Austin tonight. However, Austin is known for its vibrant music scene with many great bands and artists frequently performing in various venues across the city. You can check local event listings, music venues' websites, or event apps to find out which bands are playing in Austin tonight. Some popular music venues in Austin include Mohawk, Stubbs, Antone's, and The Continental Club. Enjoy the live music scene in Austin!\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What great bands are playing music in Austin tonight?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Chain\n",
    "\n",
    "In order to properly answer our question, we are going to need to retrieve information from the web. We can grab information from the internet using the WebBaseLoader. This loader will allow us to retrieve information from the web and use it in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install beautifulsoup4\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pull the events down from the Austin Chronicle using WebBaseLoader from langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.austinchronicle.com/events/\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Store\n",
    "Now we need to take the data we pulled from the web and convert it into a format that the model can understand. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use faiss, a very simple in memory vector store, to store the vectors of the events we pulled from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /Users/colinmcnamara/Code/austin_langchain/.venv/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can build our index\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have taken our data, split it up and stuffed into in a vector store, we can build our retrieval chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "                                        \n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to simplify things, we can pass this in directly to the retrieval chain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A great honkey tonk band is always playing at the White Horse.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"What great bands are playing music in Austin tonight?\",\n",
    "    \"context\": [Document(page_content=\"A great honkey tonk band is always playing at the White Horse\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want to pull this from our vector store, which was populated by the WebBaseLoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now invoke our chain. This returns a dictionary, with the response from the LLM in the answer key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some fun bands playing in Austin tonight are Chris Gage, Church on Monday with Elias Haslanger & Dr. James Polk, and Lonelyland with the Pat Byrne Band.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"What fun bands are playing in Austin tonight?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
