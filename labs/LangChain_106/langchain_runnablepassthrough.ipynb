{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cf3677",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/colinmcnamara/austin_langchain/blob/main/labs/LangChain_106/langchain_runnablepassthrough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d352fc-615d-4d55-a1d7-2eae5d685c31",
   "metadata": {},
   "source": [
    "# RunnableParallel, RunnablePassthrough, and itemgetter in Action\n",
    "\n",
    "1. [RunnableParallel](https://python.langchain.com/docs/expression_language/primitives/parallel/#parallelize-steps) lets you execute runnables in parallel.\n",
    "2. [RunnablePassthrough](https://python.langchain.com/docs/expression_language/primitives/passthrough/) lets you pass parameters through from one step to the next in a chain.\n",
    "3. [itemgetter](https://docs.python.org/3/library/operator.html#operator.itemgetter) returns a function that lets you extract a specific from a collection, dictionary, etc.\n",
    "\n",
    "You can use these together to create complex chains by composing simple chains.\n",
    "\n",
    "In the below example, we will construct two simple chains:\n",
    "\n",
    "1. `tweet_generator` takes prompt from a user and generates a tweet\n",
    "2. `tweet_fixer` takes a tweet and a mood from the user and generates a new tweet to match the mood\n",
    "\n",
    "We will then create a new chain `tweet_chain` that combines both of these chains into a single chain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d8acca-6cec-4ba2-bf73-fdc16795668d",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a65f4eb-19e1-4156-8c59-a3b98212717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d552ad-a8c2-4329-a55a-33a6bb6960bb",
   "metadata": {},
   "source": [
    "## Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3071235-f2a4-4b71-98ef-12b6a4310842",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Langchain releases AI middleware to create applications using LLMs. https://langchain.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26e337-73ad-4eaa-81cd-c9aa23173102",
   "metadata": {},
   "source": [
    "## LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b687b1cc-0dc8-4a29-b29b-36ce5450cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc67201-2667-4d7c-8b6c-9ef888163dab",
   "metadata": {},
   "source": [
    "## `tweet_generator` chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8897682-8802-49df-8dd4-59420268aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are an expert AI tweet generator.\n",
    "Observe the user's prompt, and generate a witty tweet, and include emojis and hashtags.\n",
    "\n",
    "Prompt: {prompt}\n",
    "Tweet: \"\"\"\n",
    ")\n",
    "tweet_generator = first_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259da5df-af5a-42e3-9e4f-396437a07114",
   "metadata": {},
   "source": [
    "## Running `tweet_generator`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e11bccd-8f3b-4eb2-9165-d483d9e677e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"üöÄ Exciting news! Langchain unveils its new AI middleware for developing apps with Language Models üíª #LLMtech #AIappdev. Say goodbye to coding headaches and hello to smarter, more efficient applications. Let\\'s build the future together! ü§ù #innovation #technology\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = tweet_generator.invoke({\"prompt\": prompt})\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f296d2-1c86-464e-945a-1e7e2322875d",
   "metadata": {},
   "source": [
    "## `tweet_fixer` chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3460871-5b5a-4ada-9dbb-4073ad3b9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are an expert AI tweet fixer.\n",
    "Fix user's original tweet and based on the mood.\n",
    "\n",
    "Original Tweet: {tweet}\n",
    "Mood: {mood}\n",
    "Fixed Tweet: \"\"\"\n",
    ")\n",
    "\n",
    "tweet_fixer = second_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde9938-5b53-4a68-b2de-854a96841f72",
   "metadata": {},
   "source": [
    "## Running `tweet_fixer` with tweet from previous response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f865c6a3-6962-4e17-85b7-5061729f49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood = \"funny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3072b9-0ca0-43df-874f-cee8fb40ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" üöÄ Fun fact: Langchain's new AI middleware for Language Model apps is so smart, it might even start coding for us next! üíª #LLMtech #AIappdev #CodingMonkeyRetired. Goodbye spaghetti code, hello sushi roll applications! Let's build a future where AI does the heavy lifting ‚Äì or at least the coding! üòÇ #innovation #technology\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_tweet = tweet_fixer.invoke(\n",
    "    {\n",
    "        \"tweet\": tweet,\n",
    "        \"mood\": mood,\n",
    "    }\n",
    ")\n",
    "fixed_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4f2aed-6fed-4b64-a608-3b0cfce1a766",
   "metadata": {},
   "source": [
    "## Combining `tweet_generator` and `tweet_fixer` into `tweet_chain`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d8bc48-d2ed-4346-9eab-3dd75873d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_chain = (\n",
    "    RunnableParallel(\n",
    "        {\"mood\": RunnablePassthrough() | itemgetter(\"mood\"), \"tweet\": tweet_generator}\n",
    "    )\n",
    "    | tweet_fixer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56b880d-3750-484b-9ef6-8ecf1232f8d3",
   "metadata": {},
   "source": [
    "## Running `tweet_chain`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e231d23-d42e-4fa2-9b98-9c11e96bc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood = \"sarcastic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43e52da-0c9b-45a7-9e6b-29cebadf0ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" üòê Oh joy, another middleware for developers to deal with. This time it's Langchain's turn with their AI offering for LLMs. Can't wait to navigate yet another integration process. #Sarcasm #AI #MachineLearning #AppDev #Langchain #TechInnovation üíªüöÄ #LanguageModels #CodeComplication\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_chain.invoke({\"prompt\": prompt, \"mood\": mood})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
